{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_building_template.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalebmes/CS376-Machine-Learning/blob/main/Phase_2_model_building_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use this notebook for the given task of the term project.\n",
        "\n",
        "### ***Make sure to delete all text cells before submission to avoid an unncessary increase of Turnitin similarity. That is, leave only the code cells.***"
      ],
      "metadata": {
        "id": "KM6QtwqX9Lw1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use only **'train.csv'**. Load the 'train.csv' file into a Pands dataframe."
      ],
      "metadata": {
        "id": "WbADjSt-lP50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dgYMJNy612-",
        "outputId": "8137d994-ff40-4b9d-cf96-ba4fadac0834"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "data_path = '/content/drive/MyDrive/CS492 term project datasets'\n",
        "data_df = pd.read_csv(os.path.join(data_path, 'train.csv'))"
      ],
      "metadata": {
        "id": "guOPsDpYjkpR"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop the 'ID', 'ProcessType', 'TransactionNature', 'Type', 'DeclarerID', 'ImporterID', 'SellerID', 'ExpressID', 'OriginCountry', 'DisplayIndicator', 'DutyRegime' attributes from the dataframe for simplicity. It doesn't mean that these attributes are unnucessary."
      ],
      "metadata": {
        "id": "wWuMDjwOoy_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropped_df = data_df.drop(columns=['ID', 'ProcessType', 'TransactionNature', 'Type', 'DeclarerID', 'ImporterID', 'SellerID', 'ExpressID', 'OriginCountry', 'DisplayIndicator','DutyRegime'])"
      ],
      "metadata": {
        "id": "6EjaJD-w-__v"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert a date value in the 'IssueDateTime' attribute to its month value. For example, `2020-01-01` $\\rightarrow$ `1`."
      ],
      "metadata": {
        "id": "GVpbLPN9pW27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropped_df['IssueDateTime'] = pd.to_datetime(dropped_df['IssueDateTime']).dt.month"
      ],
      "metadata": {
        "id": "rJW5OHlaLmvN"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keep only the first two digits in the 'ClassificationID' attribute. For example, `9619001090` $\\rightarrow$ `96`."
      ],
      "metadata": {
        "id": "waMO158XpvLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropped_df['ClassificationID'] = (dropped_df['ClassificationID']//(10e7)).astype('int')"
      ],
      "metadata": {
        "id": "3rHwbDxUBkb1"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols = ['DeclarationOfficeID', 'PaymentType', 'BorderTransportMeans', 'ExportationCountry']\n",
        "for col in cat_cols:\n",
        "  dropped_df[col] = pd.factorize(dropped_df[col], sort=True)[0]"
      ],
      "metadata": {
        "id": "L1TAZDSA9ebS"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please note that the 'DeclarationOfficeID', 'PaymentType', 'BorderTransportMeans', and 'ExportationCountry' attributes are categorical, even though some of them have numerical forms. Then, let's factorize these attributes. Here, for each unique value in an attribute, assign consecutive integer values in the increasing order of the original values. Let's call these newly assigned integers as *codes*. As an example with 'ExportationCountry', `AE` $\\rightarrow$ `0`.\n",
        "\n",
        "**Hint**: use `pd.factorize(train_df[...], sort=True)` for each of the attributes.\n",
        "\n",
        "####Q1. What is the maximum code of the 'ExportationCountry' attribute?\n",
        "\n",
        "####Q2. What is the maximum code of the 'DeclarationOfficeID' attribute?"
      ],
      "metadata": {
        "id": "MtqF56wtrTzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#answer for question number 1\n",
        "print(dropped_df['ExportationCountry'].max())\n",
        "#answer for question number 2\n",
        "print(dropped_df['DeclarationOfficeID'].max())"
      ],
      "metadata": {
        "id": "iqILv6OH_kju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a1ebebb-1ea9-471b-a519-fccd56711453"
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115\n",
            "43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the 'ClassificationID' attribute (categorical) to a set of asymmetric **binary** variables. Use `pd.get_dummies(...)`, and we do **not** want to introduce redundancy in this process (i.e., be caureful with the `drop_first` option). Keep the original dataframe and store this new one as another dataframe. \n",
        "\n",
        "#### Q3. What is the total number of columns of this **new** dataframe?\n"
      ],
      "metadata": {
        "id": "fGqoCCkVDjqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#answer for question number 3\n",
        "new_df = dropped_df.copy()\n",
        "new_df = pd.get_dummies(data=new_df, prefix='c_id_is', columns=['ClassificationID'], drop_first=True)\n",
        "print('Number of columns:', new_df.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkbiGDHPK6ql",
        "outputId": "8c629745-8345-4a0b-cf7a-99e91c2808e5"
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of columns: 103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the dataframe (immediately after **Q2**, i.e., before executing `get_dummies`) into `train_part` that contains the rows from January through September and `test_part` that contains the rows from October through December.\n",
        "\n",
        "Then, let's use `train_part` as the training set and `test_part` as the test set.\n",
        "\n",
        "####Q4. How many examples (rows) are contained in `train_part`?"
      ],
      "metadata": {
        "id": "-7BuCwcnvUiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#answer for question number 4\n",
        "train_part = dropped_df[dropped_df['IssueDateTime'] < 10]\n",
        "test_part = dropped_df[dropped_df['IssueDateTime'] > 9]\n",
        "print('number of training examples:', train_part.shape[0])"
      ],
      "metadata": {
        "id": "LOKJ7n49ZHi8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1379cc9f-87f5-427e-be5d-6d325dec72bd"
      },
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of training examples: 29158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's consider a dumb classifier that **always** returns **0**. \n",
        "\n",
        "#### Q5. What is the accuracy of the dumb classifier on the test set `test_part`?"
      ],
      "metadata": {
        "id": "bOd8PGp3HgOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#answer for question number 5\n",
        "dumb_classifier = test_part['Fake'] == 0\n",
        "acc = len(test_part[dumb_classifier]) / len(test_part)\n",
        "print(round(acc, 3))"
      ],
      "metadata": {
        "id": "AQ3XJSvF2e3A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3c70482-e854-42bf-85bd-bdcc5f56593c"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's implement a **k-nearest neighbor** classifier. To ease your implementation, please use `KNeighborsClassifier` of the scikit-learn library. Refer to the scikit-learn [manual](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html). Use the default values for all parameters except `n_neighborsint` and `weights`.\n",
        "\n",
        "Note that we want to weight points by the inverse of their distance.\n",
        "\n",
        "#### Q6. Increase the number ($k$) of neighbors from **1** through **9**. At which value of $k$, is the accuracy of the classifier on the test set `test_part` maximized?\n",
        "\n",
        "#### Q7. What is the accuracy achieved in **Q6**?"
      ],
      "metadata": {
        "id": "lhkTmNjVK4ed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#answer for question number 6\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "features = list(train_part.columns)[:-1]\n",
        "label = list(train_part.columns)[-1]\n",
        "k_max_acc = 1\n",
        "max_acc = 0\n",
        "for k in range(1, 10):\n",
        "  knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
        "  knn.fit(train_part[features], train_part[label])\n",
        "  acc = knn.score(test_part[features], test_part[label])\n",
        "  print('For k =', k, ': acc = ', acc)\n",
        "  if acc > max_acc:\n",
        "    max_acc = acc\n",
        "    k_max_acc = k\n",
        "print('maximum accuracy is obtained at k =', k_max_acc)\n",
        "#answer for question number 7\n",
        "print('and the maximum accuracy is', round(max_acc, 3))"
      ],
      "metadata": {
        "id": "InrOhzBT50zm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a25fd03f-6bf3-4f3a-a715-62ef2f046ae9"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For k = 1 : acc =  0.8461449676823638\n",
            "For k = 2 : acc =  0.8464912280701754\n",
            "For k = 3 : acc =  0.8526084949215144\n",
            "For k = 4 : acc =  0.8544552169898431\n",
            "For k = 5 : acc =  0.8509926131117267\n",
            "For k = 6 : acc =  0.8534164358264081\n",
            "For k = 7 : acc =  0.8500692520775623\n",
            "For k = 8 : acc =  0.8528393351800554\n",
            "For k = 9 : acc =  0.8533010156971376\n",
            "maximum accuracy is obtained at k = 4\n",
            "and the maximum accuracy is 0.854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeat the training and test procedures using the other dataframe obtained in **Q3**.\n",
        "\n",
        "#### Q8. Comparing the accuracy at the same value of $k$ as **Q6**~**Q7**, is the accuracy improved by using the other dataframe in **Q3**?"
      ],
      "metadata": {
        "id": "iWNXT2KQi0IY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_part = new_df[new_df['IssueDateTime'] < 10]\n",
        "test_part = new_df[new_df['IssueDateTime'] > 9]\n",
        "df = train_part.copy()\n",
        "label = 'Fake'\n",
        "df = df.drop(columns='Fake')\n",
        "features = list(df.columns)\n",
        "knn = KNeighborsClassifier(n_neighbors=k_max_acc, weights='distance')\n",
        "knn.fit(train_part[features], train_part[label])\n",
        "new_acc = knn.score(test_part[features], test_part[label])\n",
        "print('Accuracy on the new dataframe:', new_acc)\n",
        "print('Accuracy on the old dataframe:', max_acc)\n",
        "print('Is the accuracy improved?', new_acc > max_acc)"
      ],
      "metadata": {
        "id": "4hudDUF_jYY9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f9a1719-77df-462b-b4bc-2773d7ce629d"
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the new dataframe: 0.8434903047091413\n",
            "Accuracy on the old dataframe: 0.8544552169898431\n",
            "Is the accuracy improved? False\n"
          ]
        }
      ]
    }
  ]
}